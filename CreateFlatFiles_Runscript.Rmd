---
title: "Create Files for App Runscript"
author: "Sam Graf"
date: '2023-07-06'
output: html_document
---

```{r readins, include=FALSE, echo = FALSE}
library(tidyverse) 
library(lubridate)
library(readxl)
library(dataRetrieval) #this is the usgs pacakge for getting instantanous data

whole_doc_startTime <- Sys.time()
start_time <- Sys.time()
print("Reading in Stationary, Mobile, Biomark, Release, and Recapture csv files.....")

#functions
for (i in list.files("./functions/")) {
  if (grepl(".R", i)) {
    source(paste0("./functions/",i))
  }
}

for (i in list.files("./miscR/")) {
  if (grepl(".R", i)) {
    source(paste0("./miscR/",i))
  }
}

# if column names change in any of these read-ins, might require some modification to code to get them to combine
# also if you change read.csv to read_csv, it should read in quicker but column names will change
# could be a later task
Stationary <- readRDS("./data/WGFP_Raw_20240514.rds")

Mobile <- read.csv("./data/WGFP_Mobile_Detect_AllData.csv" , colClasses= c(rep("character",14), rep("numeric", 4), rep("character", 3)))

Biomark <- read.csv("./data/Biomark_Raw_20221102.csv", dec = ",") 

# need to have tagID as a numeric field in the .csv file in order to be read in correctly as opposed to 2.3E+11 

Release <- read.csv("./data/WGFP_ReleaseData_Master_20240520.csv", na.strings = c(""," ","NA"), colClasses=c(rep("character",9), "numeric", "numeric",rep("character",8)))

Recaptures <- read.csv("./data/WGFP_RecaptureData_Master_20240520.csv", na.strings = c(""," ","NA"), colClasses = c(rep("character", 8), rep("numeric", 2), rep("character", 8)))

#avian predation
AvianPredation <- read_csv("./data/WGFP_AvianPredation.csv", 
                           col_types = cols(TagID = col_character(),Comments = col_character()))

#ghost tag df
GhostTags <- read_csv("./data/WGFP_GhostTags.csv", 
                           col_types = cols(TagID = col_character()))

#metadata

wgfpMetadata <- lapply(excel_sheets("./data/WGFP Metadata.xlsx"), function(x)
  if(x == "MarkerTagIssues"){
    read_excel("./data/WGFP Metadata.xlsx", sheet = x, col_types = c("guess", "date", "date", "guess", "guess"))
  } else{
    read_excel("./data/WGFP Metadata.xlsx", sheet = x, col_types = "text")
  }
)
names(wgfpMetadata) <- excel_sheets("./data/WGFP Metadata.xlsx")

###Pressure transducer Data
pTList <- list()

for (file in list.files("data/PressureTransducer")) {
  filereadin <- read_csv(file.path("data/PressureTransducer/", file))
  filename <- unique(filereadin$Site)
  pTList[[filename]] <- filereadin
}

allPressureTransducerData <- bind_rows(pTList) %>%
  mutate(DateTime = lubridate::mdy_hm(DateTime))

## detection distance

siteVisitList <- lapply(excel_sheets("./data/WGFP_SiteVisits_FieldData.xlsx"), function(x){
  column_names <- read_excel("./data/WGFP_SiteVisits_FieldData.xlsx", sheet = x, skip = 2, n_max = 0)
  # Number of columns in the sheet
  num_cols <- length(column_names)
  # Specify the column types for the first 3 columns bc they have dates/times
  initial_col_types <- c("guess", "date", "date")
  col_types <- c(initial_col_types, rep("guess", num_cols - length(initial_col_types)))
  read_excel("./data/WGFP_SiteVisits_FieldData.xlsx", sheet = x, skip = 2, col_types = col_types)
}
  
)

names(siteVisitList) <- excel_sheets("./data/WGFP_SiteVisits_FieldData.xlsx")


end_time = Sys.time()
print(paste("Reading in files took", round((end_time-start_time),2)))


```

```{r USGSData, include = TRUE, echo = FALSE}
usgsTime <- Sys.time()
#reading in USGS data with upt to date data
windyGapDaily <- readNWISdv(siteNumbers = "09034250", #code for windy gap
                       parameterCd = c("00060", "00010"), #this is parameter codes for discharge and celsius water temp; more can be added if needed. https://help.waterdata.usgs.gov/codes-and-parameters/parameters
                       startDate = "2020-08-06", 
                       endDate = Sys.Date())
windyGapDaily <- renameNWISColumns(windyGapDaily) %>%
  mutate(WtempF = (Wtemp * 9/5) + 32)
#sometimes this can fail if USGS is having issues on their end
windyGap <- readNWISuv(siteNumbers = "09034250", #code for windy gap
                       parameterCd = c("00060", "00010"), #this is parameter code for discharge; more can be added if needed
                       startDate = "2020-08-06", #if you want to do times it is this format: "2014-10-10T00:00Z",
                       endDate = Sys.Date(),
                       tz = "America/Denver")

windyGap <- renameNWISColumns(windyGap) %>%
  mutate(Wtemp_Inst = (Wtemp_Inst * 9/5) + 32) %>%
  rename(USGSDischarge = Flow_Inst, 
         USGSWatertemp = Wtemp_Inst)
#this is to make attaching these readings to detections later
windyGap$dateTime <- lubridate::force_tz(windyGap$dateTime, tzone = "UTC") 

allPressureTransducerDataWithDischarge <- windyGap[,c("dateTime", "USGSDischarge", "USGSWatertemp")] %>%
  #we're going to get a "many" relationship here because the discharge is joined to each site reading so it causes each disharge timestamp that has a matching PT logger reading to get multiplied by at least 3 (1 for RB, HP, and CF)
  #another weird thing here: sometimes there is instances where USGSdischarge is recorded twice at the same time ie (2022-11-06 01:00:00)
  #but the values are within like 2 cfs of each other so it seems fine
  #this doesn't seem to happen with temperature
  left_join(allPressureTransducerData, by = c("dateTime"= "DateTime"), relationship = "many-to-many") %>%
  #we are getting rid of the "ice" entries here by turning them to 0
  mutate(Water_Level_NoIce_ft = as.numeric(case_when(Water_Level_NoIce_ft == "Ice" ~ "0", 
                                          TRUE ~ Water_Level_NoIce_ft)))

allPressureTransducerDataWithDischarge_Long <- allPressureTransducerDataWithDischarge %>%
  pivot_longer(cols = c(contains("_"), "USGSDischarge", "USGSWatertemp"), names_to = "EnvVariable", values_to = "Reading")

usgsTime2 <- Sys.time()
print(paste("Reading in USGS Data took", round((usgsTime2-usgsTime),2)))

```



```{r QAQCduplicateTags, include = TRUE, echo = FALSE}
#checking if ghost tags have 1 tag entry for each

problemGhostTags <- GhostTags %>%
  count(TagID) %>%
  filter(n > 1)

if(nrow(problemGhostTags) > 0){
  print(paste0("The following tags in the Ghost Tag dataframe have multiple entries in the Ghost Tag sheet: ", unique(problemGhostTags$TagID),
                                         ". Please adjust this in the original df, otherwise there will be a left_join() warning."))
}

problemAvianPredationTags <- AvianPredation %>%
  count(TagID) %>%
  filter(n > 1)

if(nrow(problemAvianPredationTags) > 0){
  print(paste0("The following tags in the Avian Predation dataframe have multiple entries: ", unique(problemAvianPredationTags$TagID),
                                         ". Please adjust this in the original df, otherwise there will be a left_join() warning."))
}

problemReleaseTags <- Release %>%
  count(TagID) %>%
  filter(n > 1)

if(nrow(problemReleaseTags) > 0){
  print(paste0("The following tags in the Release dataframe have multiple entries: ", as.character(unique(problemReleaseTags$TagID)),
                                         ". Please adjust this in the original df."))
}
```


```{r metadatavariables, include=FALSE, echo = FALSE}
###Variables that are used throughout the funcitons
###Frontend (display) codes
TestBiomarkAntennaFrontendSiteCode <- as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Biomark test Antenna in random spot", "FrontendSiteCode"])

WindyGapBypassAntennaFrontendSiteCode <- as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Windy Gap Bypass Channel", "FrontendSiteCode"])

WindyGapAuxiliaryAntennaFrontendSiteCode <- as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Windy Gap Auxiliary", "FrontendSiteCode"])

GranbyDiversionAntennaFrontendSiteCode <- as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Granby Diversion", "FrontendSiteCode"])

RiverRunAntennaFrontendSiteCode <- as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "River Run", "FrontendSiteCode"])

FraserRiverCanyonAntennaFrontendSiteCode <- as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Fraser River Canyon", "FrontendSiteCode"])

RedBarnFrontendCodes <- unname(unlist(as.vector(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$SiteName) & wgfpMetadata$AntennaMetadata$SiteName == "Red Barn Stationary Antenna", "FrontendSiteCode"])))

HitchingPostFrontendCodes <- unname(unlist(as.vector(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$SiteName) & wgfpMetadata$AntennaMetadata$SiteName == "Hitching Post Stationary Antenna", "FrontendSiteCode"])))

ConfluenceFrontendCodes <- unname(unlist(as.vector(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$SiteName) & wgfpMetadata$AntennaMetadata$SiteName == "Confluence Stationary Antenna", "FrontendSiteCode"])))

MobileRunFrontendCodes <- unname(unlist(as.vector(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$SiteName) & wgfpMetadata$AntennaMetadata$SiteName == "Mobile Run", "FrontendSiteCode"])))

ConnectivityChannelDownstreamFrontendCodes <- unname(unlist(as.vector(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$SiteName) & wgfpMetadata$AntennaMetadata$SiteName == "Connectivity Channel Downstream Stationary Antenna", "FrontendSiteCode"])))

ConnectivityChannelSideChannelFrontendCodes <- unname(unlist(as.vector(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$SiteName) & wgfpMetadata$AntennaMetadata$SiteName == "Connectivity Channel Side Channel Stationary Antenna", "FrontendSiteCode"])))

ConnectivityChannelUpstreamFrontendCodes <- unname(unlist(as.vector(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$SiteName) & wgfpMetadata$AntennaMetadata$SiteName == "Connectivity Channel Upstream Stationary Antenna", "FrontendSiteCode"])))

# ##############BACKEND CODES
TestBiomarkAntennaBackendSiteCode <- as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Biomark test Antenna in random spot", "BackendSiteCode"])

WindyGapBypassAntennaBackendSiteCode <- as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Windy Gap Bypass Channel", "BackendSiteCode"])

WindyGapAuxiliaryAntennaBackendSiteCode <- as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Windy Gap Auxiliary", "BackendSiteCode"])


GranbyDiversionAntennaBackendSiteCode <- unlist(strsplit(as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Granby Diversion", "BackendSiteCode"]), ",\\s*"))

RiverRunAntennaBackendSiteCode <- unlist(strsplit(as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "River Run", "BackendSiteCode"]), ",\\s*"))

FraserRiverCanyonAntennaBackendSiteCode <- unlist(strsplit(as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Fraser River Canyon", "BackendSiteCode"]), ",\\s*"))

test_tags <- unique(wgfpMetadata$TestTags$TAG)
fraserColoradoRiverConfluence <- as.numeric(wgfpMetadata$ImportantStationingVariables[wgfpMetadata$ImportantStationingVariables$Variable == "Fraser/Colorado River Confluence", "StationingLocation"])

DamLocation <- as.numeric(wgfpMetadata$ImportantStationingVariables[wgfpMetadata$ImportantStationingVariables$Variable == "Windy Gap Dam", "StationingLocation"])

metaDataVariableNames <- list(
  "TestBiomarkAntennaBackendSiteCode" = TestBiomarkAntennaBackendSiteCode, 
  "TestBiomarkAntennaFrontendSiteCode" = TestBiomarkAntennaFrontendSiteCode, 
  "WindyGapBypassAntennaFrontendSiteCode" = WindyGapBypassAntennaFrontendSiteCode,
  "WindyGapAuxiliaryAntennaFrontendSiteCode" = WindyGapAuxiliaryAntennaFrontendSiteCode,
  "GranbyDiversionAntennaFrontendSiteCode" = GranbyDiversionAntennaFrontendSiteCode,
  "RiverRunAntennaFrontendSiteCode" = RiverRunAntennaFrontendSiteCode,
  "FraserRiverCanyonAntennaFrontendSiteCode" = FraserRiverCanyonAntennaFrontendSiteCode,
  "RedBarnFrontendCodes" = RedBarnFrontendCodes,
  "HitchingPostFrontendCodes" = HitchingPostFrontendCodes,
  "ConfluenceFrontendCodes" = ConfluenceFrontendCodes,
  "MobileRunFrontendCodes" = MobileRunFrontendCodes,
  "ConnectivityChannelDownstreamFrontendCodes" = ConnectivityChannelDownstreamFrontendCodes,
  "ConnectivityChannelSideChannelFrontendCodes" = ConnectivityChannelSideChannelFrontendCodes,
  "ConnectivityChannelUpstreamFrontendCodes" = ConnectivityChannelUpstreamFrontendCodes,
  "WindyGapBypassAntennaBackendSiteCode" = WindyGapBypassAntennaBackendSiteCode,
  "WindyGapAuxiliaryAntennaBackendSiteCode" = WindyGapAuxiliaryAntennaBackendSiteCode,
  "GranbyDiversionAntennaBackendSiteCode" = GranbyDiversionAntennaBackendSiteCode,
  "RiverRunAntennaBackendSiteCode" = RiverRunAntennaBackendSiteCode,
  "FraserRiverCanyonAntennaBackendSiteCode" = FraserRiverCanyonAntennaBackendSiteCode,
  "AntennaSiteShortHandCodes" = sort(unique(wgfpMetadata$AntennaMetadata$AntennaSiteShortHandShorthand)), 
  "allPressureTransducerSiteNames" = sort(unique(wgfpMetadata$AntennaMetadata$PressureTransducerSiteName)),
  "allDetectionDistanceSiteNames" = sort(unique(wgfpMetadata$AntennaMetadata$DetectionDistanceSiteName)),
  "test_tags" = test_tags,
  "fraserColoradoRiverConfluence" = fraserColoradoRiverConfluence,
  "DamLocation" = DamLocation
)

```

```{r cleaningForFunctions, include=FALSE, echo=FALSE}

#### This part is for checking if new antennas to be put in will work
#neeed to keep this in because it adds a column for the new antennas which sets up the enc_hist_wide_list for the new antennas
#the actual dummy tag is taken out at the end though

dummy_rows_list <- add_dummy_rows(stationary1 = Stationary, biomark1 = Biomark, release1 = Release)
#Stationary <- dummy_rows_list$Stationary
Biomark <- dummy_rows_list$Biomark
Release <- dummy_rows_list$Release
#ghost_tag_df <- dummy_rows_list$Ghost_tags #date column is named "Ghost_date" and is a date type

# Date Wrangling ----------------------------------------------------------

utmsStationary <- addUTMsAndReformatStationary(Stationary = Stationary)

# this readies raw files to be put into functions as well as displayed on Indivudal Datasets Page
Mobile <- Mobile %>%
    mutate(Date = as.character(lubridate::mdy(Date)))


Biomark <- Biomark %>%
  #make a column for Scan>Date if parentheses are detected in the string, that means the format is in mdy
  # and we want to convert it to YYYYMMDD format. elsewise, leave it as is
  mutate(Scan.Date = ifelse(str_detect(Scan.Date, "/"),
                            as.character(lubridate::mdy(Scan.Date)),
                            Scan.Date))


cleanedRelease <- Release %>%
  mutate(Date = as.character(lubridate::mdy(Date)))

cleanedRecaptures <- Recaptures %>%
  mutate(Date = as.character(lubridate::mdy(Date)))

AvianPredation <- AvianPredation %>%
  mutate(PredationDate = lubridate::mdy(PredationDate))

GhostTags <- GhostTags %>%
  mutate(GhostDate = lubridate::mdy(GhostDate))
```

```{r wrangling, include=TRUE, echo = FALSE}


#putting detection data into a function that cleans and readies data for wrangling, display, filtering, mapping, plotting
df_list <- All_combined_events_function(Stationary = utmsStationary, Mobile = Mobile, Release = Release, Biomark = Biomark, Recaptures = Recaptures)

#separating to marker tag file and fish detections file

#all marker tags here
Cleaned_Marker_tags <- df_list$All_Detections %>%
  dplyr::filter(str_detect(TAG, "^0000000|^999")) %>%
  mutate(Scan_Date = ymd(Scan_Date))

Cleaned_Stationary_FishdetectionsOnly <- utmsStationary %>%
  filter(grepl("^230|^226", TAG))


#spatially joins point (detection) data to lines (station) data based on nearest feature.
#simpleStations is from polygon_readins
DailyMovements_withStations <- spatial_join_stations_detections(df_list$All_Events_most_relevant, simpleStations = simpleStations)

if(nrow(DailyMovements_withStations$noUTMS) > 0){
  print(paste0("The following tags could not be assigned stations becuase of an NA entry for UTMs: ", unique(DailyMovements_withStations$noUTMS$TAG),
                                         "."))
}

#prepares joined stations and relevant Movements dataset for movements summaries and states

combined_events_stations <- PrepareforStatesMovementsandSummary(DailyMovements_withStations$stationData)

# states
states_data_list <- states_function(combined_events_stations, GhostTags, AvianPredation)
# aplies enc_hist_summary wide function
enc_hist_wide_list <- Ind_tag_enc_hist_wide_summary_function(df_list$Recaps_detections, cleanedRelease, combined_events_stations, states_data_list$States_summarized, markerTags = unique(Cleaned_Marker_tags$TAG))
unknown_tags <- enc_hist_wide_list$Unknown_Tags
enc_hist_wide_df <- enc_hist_wide_list$encountersAndRelease_wide_summary
# applies get_movements_function
Movements_df <- get_movements_function(combined_events_stations, dailyUSGSData = windyGapDaily)
WeeklyMovementsbyType <- WrangleMinicharts_function(Movements_df)

###QAQC ghost tags
ghostTagsWithMovementAfterGhostDate <- qaqcGhostTagMovements(GhostTags, Movements_df)

#this is used in states_data reactives
weeks <- data.frame(weeks_since = min(states_data_list$All_States$weeks_since):max(states_data_list$All_States$weeks_since))

#more formatting
Enc_release_data <- enc_hist_wide_df %>%
    mutate(Date = ifelse(str_detect(Date, "/"),
                         as.character(lubridate::mdy(Date)),
                         Date)) %>%
  rename(ReleaseDate = Date)


# if someone could incorporate and expland upon this custom rainbow trout color pallette I made that would be great
rainbow_trout_pallette <- list(pink1 = "#E3BABBFF", olive_green1 = "#C4CFBFFF", dark_olive_green1 = "#81754EFF",
                               mustard_yellow1 = "#CBA660FF", brown_yellow = "#86551CFF" )

WGFP_SiteVisits_FieldData <- wrangleSiteVisitData(siteVisitList = siteVisitList)
WGFP_SiteVisits_FieldDatawithPTData <- combineEnvironmentalAndSiteVisitData(WGFPSiteVisitsFieldData = WGFP_SiteVisits_FieldData, PTDataWide = allPressureTransducerDataWithDischarge)

### taking dummy tag out

Biomark <- Biomark #%>%
  #filter(!DEC.Tag.ID %in% c("900.230000999999"))
cleanedRelease <- cleanedRelease #%>%
  #filter(!TagID %in% c("230000999999"))
Stationary <- Cleaned_Stationary_FishdetectionsOnly #%>%
  #filter(!TAG %in% c("900230000999999"))

#this list is taken by the individual datasets mod
indiv_datasets_list_og <- list(
  "stationarycleandata" = Stationary,
  "biomarkdata" = Biomark,
  "mobiledata" = Mobile,
  "recapdata" = cleanedRecaptures,
  "releasedata" = cleanedRelease,
  "ghostdata" = GhostTags,
  "avian_preddata" = AvianPredation, 
  "PTDataRawCombined" = allPressureTransducerData,
  "USGSData15Min" = windyGap,
  "SiteVisitDataCombined" = WGFP_SiteVisits_FieldData
)

indiv_datasets_list <- lapply(names(indiv_datasets_list_og), function(name) {
  dataset <- indiv_datasets_list_og[[name]]
  if (name %in% c("PTDataRawCombined", "USGSData15Min", "SiteVisitDataCombined")) {
    return(dataset)  # Skip processing for these datasets
  } else {
    # Perform the cleaning operation
    return(dataset[!apply(is.na(dataset) | dataset == "", 1, all), ])
  }
})
names(indiv_datasets_list) <- names(indiv_datasets_list_og)

movements_list <- list(
  "Movements_df" = Movements_df,
  "WeeklyMovementsbyType" = WeeklyMovementsbyType, 
  "ghostTagsWithMovementAfterGhostDate" = ghostTagsWithMovementAfterGhostDate
)

PTData <- list(
  "PTDataWide" = allPressureTransducerDataWithDischarge, 
  "PTDataLong" = allPressureTransducerDataWithDischarge_Long
)

USGSData <- list(
  "USGS15Min" = windyGap, 
  "USGSDaily" = windyGapDaily
)

SiteVisitData <- list(
  "WGFP_SiteVisits_FieldData" = WGFP_SiteVisits_FieldData, 
  "SiteVisitAndPTData" = WGFP_SiteVisits_FieldDatawithPTData
)



```

```{r saveFiles, include = TRUE, echo=FALSE}
saveFilestartTime <- Sys.time()
allFlatFiles <- list(
  "combinedData_df_list" = df_list,
  "indiv_datasets_list" = indiv_datasets_list,
  "Enc_release_data" = Enc_release_data,
  "states_data_list" = states_data_list,
  "movements_list" = movements_list,
  "Marker_tags" = Cleaned_Marker_tags,
  "unknown_tags" = unknown_tags, 
  "wgfpMetadata" = wgfpMetadata,
  "metaDataVariableNames" = metaDataVariableNames,
  "PTData" = PTData,
  "USGSData" = USGSData, 
  "SiteVisitData" = SiteVisitData
)

for(filename in names(allFlatFiles)){
  saveRDS(allFlatFiles[[filename]], paste0("data/flatFilesforApp/", filename, ".rds"))
}
saveFilesEndTime <- Sys.time()

print(paste("Saving Files took", round(difftime(saveFilesEndTime, saveFilestartTime, units = "mins"),2), "minutes"))

whole_doc_endTime <- Sys.time()
```


## `r paste("The whole document took", round(whole_doc_endTime-whole_doc_startTime,2), "minutes to run.  Flat Files are saved to the flat files directory and the data vis app is ready to run with the most updated data.")`
